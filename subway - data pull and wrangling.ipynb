{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf914427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import MultiPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e325fd",
   "metadata": {},
   "source": [
    "### API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ea07b",
   "metadata": {},
   "source": [
    "        Census — Zip Codes Business Patterns: https://www.census.gov/data/developers/data-sets/cbp-zbp/zbp-api.2018.html#list-tab-353702932\n",
    "                2013 variables: https://api.census.gov/data/2013/zbp/variables.html\n",
    "                2018 variables: https://api.census.gov/data/2018/zbp/variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ee4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2013,2018]\n",
    "\n",
    "# dictionary to store separate year df\n",
    "zbp_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/zbp'\n",
    "\n",
    "    params = {\n",
    "        'get': 'EMP,ESTAB',     # employee count and establishment count\n",
    "        'for': 'zipcode:*'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params = params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data[1:], columns = data[0])\n",
    "\n",
    "            # fix column headers\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df = df.rename(columns = {'emp':'employee_count','estab':'business_count','zip code':'zip_code'})\n",
    "        \n",
    "            # filter zichangeodes → 10s & 11s grabs NYC + lower tier → https://simple.wikipedia.org/wiki/List_of_ZIP_Code_prefixes\n",
    "        df = df[df['zip_code'].str.startswith(('10', '11'))].reset_index(drop = True)\n",
    "        zbp_dict[year] = df\n",
    "    else:\n",
    "        print(f\"Error for {year}: {response.status_code}, {response.text}\")\n",
    "\n",
    "zbp13_df = zbp_dict[2013]\n",
    "zbp18_df = zbp_dict[2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1af17e",
   "metadata": {},
   "source": [
    "        Census — American Community Survey 5-Year: https://www.census.gov/data/developers/data-sets/acs-5year.2018.html#list-tab-1806015614\n",
    "                2013 variables: https://api.census.gov/data/2013/acs/acs5/variables.html\n",
    "                2018 variables: https://api.census.gov/data/2018/acs/acs5/variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4acc8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store separate year df\n",
    "acs_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5'\n",
    "\n",
    "    params = {\n",
    "        'get':'B01003_001E',                   # total population estimate\n",
    "        'for':'zip code tabulation area:*',    # ZCTAs not ZIPs\n",
    "        'in':'state:36'                        # 36 = new york \n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params = params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data[1:], columns = data[0])\n",
    "        \n",
    "            # fix column headers\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df = df.rename(columns = {'b01003_001e':'population','zip code tabulation area':'zcta'})\n",
    "        acs_dict[year] = df\n",
    "    else:\n",
    "        print(f'Error for {year}: {response.status_code}, {response.text}')\n",
    "\n",
    "acs13_df = acs_dict[2013]\n",
    "acs18_df = acs_dict[2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d71b5",
   "metadata": {},
   "source": [
    "        Employment data uses ZIP and population data uses ZCTA so we need to use a crosswalk to merge\n",
    "\n",
    "        HRSA ZIP to ZCTA Crosswalk: https://data.hrsa.gov/DataDownload/GeoCareNavigator/ZIP%20Code%20to%20ZCTA%20Crosswalk.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4d058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_excel('ZIP Code to ZCTA Crosswalk.xlsx')\n",
    "cross_df.columns = cross_df.columns.str.lower()\n",
    "cross_df = cross_df[cross_df['state'] == 'NY']\n",
    "cross_df['zcta'] = cross_df['zcta'].astype(int)\n",
    "cross_df = cross_df[['zip_code','zcta','zip_join_type']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e9002",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a51bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to ZBP to get one row per ZIP\n",
    "zbp_merged = pd.merge(zbp18_df, zbp13_df, on = 'zip_code', how = 'left')\n",
    "zbp_merged = zbp_merged.rename(columns = {'employee_count_x':'employee_count_2018','business_count_x':'business_count_2018','employee_count_y':'employee_count_2013','business_count_y':'business_count_2013'})\n",
    "zbp_merged = zbp_merged[['zip_code','employee_count_2013','employee_count_2018','business_count_2013','business_count_2018']].astype(int)\n",
    "\n",
    "# merge to ACS to get one row per ZCTA\n",
    "acs_merged = pd.merge(acs18_df, acs13_df, on = 'zcta', how = 'left')\n",
    "acs_merged = acs_merged.rename(columns = {'population_x':'population_2018','population_y':'population_2013'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b64247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use crosswalk to convert ZCTA to ZIP\n",
    "acs_merged['zcta'] = acs_merged['zcta'].astype(int)\n",
    "acs_merged = pd.merge(acs_merged, cross_df, on = 'zcta', how = 'left')\n",
    "acs_merged = acs_merged[acs_merged['zip_code'].astype(str).str.startswith(('10', '11'))].reset_index(drop = True)\n",
    "\n",
    "# some duplicated ZIPs → keep 'ZIP matches ZCTA' but if that isn't true for a zip, then use 'Spaital join to ZCTA'\"ZIP Code to ZCTA Crosswalk.xlsx\"\n",
    "acs_merged['priority'] = (acs_merged['zip_join_type'] == 'Zip matches ZCTA').astype(int)\n",
    "acs_merged = acs_merged.sort_values(by = ['zip_code','priority'], ascending = [True, False]).drop_duplicates(subset = 'zip_code', keep = 'first').reset_index(drop = True)\n",
    "acs_merged = acs_merged[['zip_code','population_2013','population_2018']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d716cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ZBP and ACS\n",
    "zip_df = pd.merge(zbp_merged, acs_merged, on = 'zip_code', how = 'left')\n",
    "zip_df = zip_df.dropna().reset_index(drop = True)     # 4 rows did not merge with population data → drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c67760",
   "metadata": {},
   "source": [
    "### BigQuery public data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77734d",
   "metadata": {},
   "source": [
    "        Zip Code Geometry\n",
    "        Subway Station Ridership and Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552fefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_geo_df = pd.read_csv('NYC zip geometry.csv')\n",
    "sub_df = pd.read_csv('subway ridership.csv')\n",
    "#separate geometry and boroughs\n",
    "sub_geo = sub_df[['station','borough','station_geom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da525a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIP level population and employment still contains ZIPs that are not in NYC\n",
    "# geometry data contains only NYC, excluding Staten Island\n",
    "nyc_df = pd.merge(zip_geo_df, zip_df, on = 'zip_code', how = 'left')\n",
    "nyc_df = nyc_df.dropna().reset_index(drop = True)       # 1 row did not merge with population data → drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e63c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subway data is partitioned by station and route → group by \n",
    "sub_df['route_count'] = sub_df['route'].str.split().apply(len)      # count the train lines in the row\n",
    "sub_df = sub_df[['station','borough','route_count','ridership_2013','ridership_2018']]\n",
    "sub_df = sub_df.groupby(['station','borough']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a69910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the geometry points are different for duplicate rows of the same station\n",
    "# this probably means the points are something like entrences instead of the center point of the station → need to get center\n",
    "sub_geo['station_geom'] = sub_geo['station_geom'].apply(wkt.loads)\n",
    "sub_geo = gpd.GeoDataFrame(sub_geo, geometry = 'station_geom', crs = 'EPSG:4326')\n",
    "sub_geo = sub_geo.groupby(['station', 'borough'], as_index = False)['station_geom'].agg(lambda s: MultiPoint(list(s)).centroid)\n",
    "\n",
    "# merge back with ridership data\n",
    "sub_df = pd.merge(sub_df, sub_geo, on = ['station', 'borough'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42eca77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into geo dataframe\n",
    "sub_gdf = gpd.GeoDataFrame(sub_df, geometry = 'station_geom', crs = 'EPSG:4326')\n",
    "nyc_df['zip_code_geom'] = nyc_df['zip_code_geom'].apply(wkt.loads)\n",
    "nyc_gdf = gpd.GeoDataFrame(nyc_df, geometry = 'zip_code_geom', crs = 'EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0299f3",
   "metadata": {},
   "source": [
    "### Spatial Buffering → what zip codes are within 0.5 miles of a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69395cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change crs for better accuracy → feet instead of degrees\n",
    "sub_gdf = sub_gdf.to_crs(epsg = 2263)\n",
    "nyc_gdf = nyc_gdf.to_crs(epsg = 2263)\n",
    "\n",
    "# create a 0.5 mile buffer & set this as the active geometry column\n",
    "sub_gdf['buffer_geom'] = sub_gdf.geometry.buffer(2640)\n",
    "sub_gdf = sub_gdf.set_geometry('buffer_geom')\n",
    "\n",
    "# only keep station, borough and the buffer geom\n",
    "sub_gdf = sub_gdf[['station','borough','buffer_geom']]\n",
    "\n",
    "# spatial join → get zip codes that intersect with the buffer\n",
    "zips_near_station = gpd.sjoin(nyc_gdf, sub_gdf[['station','borough','buffer_geom']], how = 'inner', predicate = 'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df980362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join row multiplies → a row for each station to zip combination → groupby on stations\n",
    "spatial_df = zips_near_station[['station','population_2013','population_2018','employee_count_2013','employee_count_2018','business_count_2013','business_count_2018']]\n",
    "spatial_df = spatial_df.groupby('station').sum().reset_index()\n",
    "\n",
    "# add back ridership data and add borough for control\n",
    "spatial_df = pd.merge(spatial_df, sub_df, on = 'station', how = 'left')\n",
    "#spatial_df = pd.merge(spatial_df, sub_boro, on = 'station', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7212337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add growth / decline\n",
    "spatial_df['rider_change'] = spatial_df['ridership_2018'] - spatial_df['ridership_2013']\n",
    "spatial_df['pop_change'] = spatial_df['population_2018'] - spatial_df['population_2013']\n",
    "spatial_df['emp_change'] = spatial_df['employee_count_2018'] - spatial_df['employee_count_2013']\n",
    "spatial_df['bus_change'] = spatial_df['business_count_2018'] - spatial_df['business_count_2013']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738ec98",
   "metadata": {},
   "source": [
    "### Save off dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for regression\n",
    "spatial_df.to_csv('regression data.csv', index = False)\n",
    "\n",
    "# zip codes that are within the buffer zone → for mapping\n",
    "buffer_zip_list = zips_near_station['zip_code'].unique()\n",
    "buffer_zip_df = nyc_df[nyc_df['zip_code'].isin(buffer_zip_list)]\n",
    "buffer_zip_df.to_csv('zip codes close to subways.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
