{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf914427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import MultiPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a258f2d",
   "metadata": {},
   "source": [
    "### Subway Data Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38dbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subway data\n",
    "joined_df = pd.read_csv('subway ridership - joined.csv').drop('s_table_station_name', axis = 1)\n",
    "unjoined_df = pd.read_excel('subway unjoined - fix.xlsx', sheet_name = 'final').drop('s_table_station_name', axis = 1)\n",
    "comp_id_df = pd.read_csv('unique complexes.csv').drop('count_', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2c0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\2463919523.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  ].applymap(lambda x:wkt.loads(x) if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# make sure points are geometry format not strings\n",
    "unjoined_df[['first_point','second_point','third_point','fourth_point']] = unjoined_df[['first_point','second_point','third_point','fourth_point']\n",
    "                                                                                        ].applymap(lambda x:wkt.loads(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66be8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_cols = ['first_point','second_point','third_point','fourth_point']\n",
    "\n",
    "def get_centroid(row):\n",
    "    # filter out nulls\n",
    "    points = [p for p in row[geom_cols] if p is not None and not pd.isna(p)]\n",
    "    if len(points) == 0:\n",
    "        return None\n",
    "    if len(points) == 1:\n",
    "        return points[0]\n",
    "    # create centroid point\n",
    "    return MultiPoint(points).centroid\n",
    "\n",
    "unjoined_df['station_geom'] = unjoined_df.apply(get_centroid, axis = 1)\n",
    "\n",
    "# drop unnecessary cols\n",
    "unjoined_df = unjoined_df.drop(['first_point','second_point','third_point','fourth_point'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6927aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the two dataframes\n",
    "sub_df = pd.concat([joined_df, unjoined_df])\n",
    "sub_df = sub_df.rename(columns = {'r_table_station_name': 'station_complex_name'})\n",
    "\n",
    "# add unique copmlex ids → determine if station is local stop vs transfer hub\n",
    "sub_df = pd.merge(sub_df, comp_id_df, on = 'complex_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938d511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_complex_name    0\n",
       "routes                  0\n",
       "ridership_2013          5\n",
       "ridership_2018          1\n",
       "complex_id              0\n",
       "borough                 0\n",
       "station_geom            0\n",
       "complex_id_unique       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nulls\n",
    "sub_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6204c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all our merged and created columns have no nulls\n",
    "# nulls for ridership → likely has something to do with stops that may not have been open during 2013 or 2018 → drop them\n",
    "sub_df = sub_df.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99c1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra characters from routes col\n",
    "sub_df['routes'] = sub_df['routes'].str.replace(',', '')\n",
    "sub_df['routes'] = sub_df['routes'].str.replace('/', '')\n",
    "sub_df['routes'] = sub_df['routes'].str.replace(' ', '')\n",
    "\n",
    "# now we can count the characters to count the number of subway lines\n",
    "sub_df['route_count'] = sub_df['routes'].str.len()\n",
    "\n",
    "# add back spaces between routes for better readability\n",
    "sub_df['routes'] = sub_df['routes'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e325fd",
   "metadata": {},
   "source": [
    "### API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ea07b",
   "metadata": {},
   "source": [
    "        Census — Zip Codes Business Patterns: https://www.census.gov/data/developers/data-sets/cbp-zbp/zbp-api.2018.html#list-tab-353702932\n",
    "                2013 variables: https://api.census.gov/data/2013/zbp/variables.html\n",
    "                2018 variables: https://api.census.gov/data/2018/zbp/variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ee4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2013,2018]\n",
    "\n",
    "# dictionary to store separate year df\n",
    "zbp_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/zbp'\n",
    "\n",
    "    params = {\n",
    "        'get': 'EMP,ESTAB',     # employee count and establishment count\n",
    "        'for': 'zipcode:*'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params = params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data[1:], columns = data[0])\n",
    "\n",
    "            # fix column headers\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df = df.rename(columns = {'emp':'employee_count','estab':'business_count','zip code':'zip_code'})\n",
    "        \n",
    "            # filter zichangeodes → 10s & 11s grabs NYC + lower tier → https://simple.wikipedia.org/wiki/List_of_ZIP_Code_prefixes\n",
    "        df = df[df['zip_code'].str.startswith(('10', '11'))].reset_index(drop = True)\n",
    "        zbp_dict[year] = df\n",
    "    else:\n",
    "        print(f\"Error for {year}: {response.status_code}, {response.text}\")\n",
    "\n",
    "zbp13_df = zbp_dict[2013]\n",
    "zbp18_df = zbp_dict[2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1af17e",
   "metadata": {},
   "source": [
    "        Census — American Community Survey 5-Year: https://www.census.gov/data/developers/data-sets/acs-5year.2018.html#list-tab-1806015614\n",
    "                2013 variables: https://api.census.gov/data/2013/acs/acs5/variables.html\n",
    "                2018 variables: https://api.census.gov/data/2018/acs/acs5/variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acc8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store separate year df\n",
    "acs_dict = {}\n",
    "\n",
    "acs_variables = ['B01003_001E','B01001_001E','B01001_026E','B01002_001E',\n",
    "                 'B01001_007E','B01001_008E','B01001_009E','B01001_010E','B01001_011E','B01001_012E','B01001_013E',\n",
    "                 'B01001_031E','B01001_032E','B01001_033E','B01001_034E','B01001_035E','B01001_036E','B01001_037E',\n",
    "                 'B19013_001E','B25064_001E','B25001_001E','B25003_003E','B25003_001E']\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5'\n",
    "\n",
    "    params = {\n",
    "        'get':','.join(acs_variables),                   # total population estimate\n",
    "        'for':'zip code tabulation area:*',    # ZCTAs not ZIPs\n",
    "        'in':'state:36'                        # 36 = new york \n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params = params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data[1:], columns = data[0])\n",
    "        \n",
    "            # fix column headers\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df = df.rename(columns = {'zip code tabulation area':'zcta','b01003_001e':'population','b01001_001e':'male_pop','b01001_026e':'female_pop','b01002_001e':'median_age',\n",
    "                                  'b01001_007e':'male_18_19','b01001_008e':'male_20','b01001_009e':'male_21','b01001_010e':'male_22_24',\n",
    "                                  'b01001_011e':'male_25_29','b01001_012e':'male_30_34','b01001_013e':'male_35_39',\n",
    "                                  'b01001_031e':'female_18_19','b01001_032e':'female_20','b01001_033e':'female_21','b01001_034e':'female_22_24',\n",
    "                                  'b01001_035e':'female_25_29','b01001_036e':'female_30_34','b01001_037e':'female_35_39',\n",
    "                                  'b19013_001e':'median_household_income','b25064_001e':'median_gross_rent','b25001_001e':'housing_units',\n",
    "                                  'b25003_003e':'renter_occupied','b25003_001e':'occupied_total'})\n",
    "        acs_dict[year] = df\n",
    "    else:\n",
    "        print(f'Error for {year}: {response.status_code}, {response.text}')\n",
    "\n",
    "acs13_df = acs_dict[2013]\n",
    "acs18_df = acs_dict[2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d71b5",
   "metadata": {},
   "source": [
    "        Employment data uses ZIP and population data uses ZCTA so we need to use a crosswalk to merge\n",
    "\n",
    "        HRSA ZIP to ZCTA Crosswalk: https://data.hrsa.gov/DataDownload/GeoCareNavigator/ZIP%20Code%20to%20ZCTA%20Crosswalk.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4d058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_excel('ZIP Code to ZCTA Crosswalk.xlsx')\n",
    "cross_df.columns = cross_df.columns.str.lower()\n",
    "cross_df = cross_df[cross_df['state'] == 'NY']\n",
    "cross_df['zcta'] = cross_df['zcta'].astype(int)\n",
    "cross_df = cross_df[['zip_code','zcta','zip_join_type']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e9002",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "415bd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [acs13_df,acs18_df]\n",
    "\n",
    "acs_df_dict = {}\n",
    "\n",
    "for year, df in zip(years, df_list):\n",
    "    df['m_18_24'] = df['male_18_19'].astype(int) + df['male_20'].astype(int) + df['male_21'].astype(int) + df['male_22_24'].astype(int)\n",
    "    df['f_18_24'] = df['female_18_19'].astype(int) + df['female_20'].astype(int) + df['female_21'].astype(int) + df['female_22_24'].astype(int)\n",
    "    df['m_25_39'] = df['male_25_29'].astype(int) + df['male_30_34'].astype(int) + df['male_35_39'].astype(int)\n",
    "    df['f_25_39'] = df['female_25_29'].astype(int) + df['female_30_34'].astype(int) + df['female_35_39'].astype(int)\n",
    "    df['age_18_24'] = df['m_18_24'].astype(int) + df['f_18_24'].astype(int)\n",
    "    df['age_25_39'] = df['m_25_39'].astype(int) + df['f_25_39'].astype(int)\n",
    "\n",
    "    acs_df_dict[year] = df.copy()\n",
    "\n",
    "\n",
    "acs13_df = acs_df_dict[2013]\n",
    "acs18_df = acs_df_dict[2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd81db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary cols\n",
    "acs13_df = acs13_df[['zcta','population', 'male_pop', 'female_pop', 'median_age','age_18_24', 'age_25_39',\n",
    "          'median_household_income', 'median_gross_rent', 'housing_units','renter_occupied', 'occupied_total']].astype(float)\n",
    "acs18_df = acs18_df[['zcta','population', 'male_pop', 'female_pop', 'median_age','age_18_24', 'age_25_39',\n",
    "          'median_household_income', 'median_gross_rent', 'housing_units','renter_occupied', 'occupied_total']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45adeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cols\n",
    "acs13_df = acs13_df.rename(columns = {'population':'pop_2013', 'male_pop':'male_pop_2013', 'female_pop':'female_pop_2013',\n",
    "                           'median_age':'median_age_2013','age_18_24':'college_early_prof_2013', 'age_25_39':'young_prof_2013',\n",
    "                           'median_household_income':'median_income_2013', 'median_gross_rent':'median_rent_2013',\n",
    "                           'housing_units':'housing_units_2013','renter_occupied':'renter_occupied_2013', 'occupied_total':'occupied_total_2013'})\n",
    "\n",
    "acs18_df = acs18_df.rename(columns = {'population':'pop_2018', 'male_pop':'male_pop_2018', 'female_pop':'female_pop_2018',\n",
    "                           'median_age':'median_age_2018','age_18_24':'college_early_prof_2018', 'age_25_39':'young_prof_2018',\n",
    "                           'median_household_income':'median_income_2018', 'median_gross_rent':'median_rent_2018',\n",
    "                           'housing_units':'housing_units_2018','renter_occupied':'renter_occupied_2018', 'occupied_total':'occupied_total_2018'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4c175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to ACS to get one row per ZCTA\n",
    "acs_merged = pd.merge(acs18_df, acs13_df, on = 'zcta', how = 'left')\n",
    "\n",
    "# there are 0s and negative values → make them nulls for now\n",
    "acs_merged[acs_merged <= 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59a51bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to ZBP to get one row per ZIP\n",
    "zbp_merged = pd.merge(zbp18_df, zbp13_df, on = 'zip_code', how = 'left')\n",
    "zbp_merged = zbp_merged.rename(columns = {'employee_count_x':'employee_count_2018','business_count_x':'business_count_2018','employee_count_y':'employee_count_2013','business_count_y':'business_count_2013'})\n",
    "zbp_merged = zbp_merged[['zip_code','employee_count_2013','employee_count_2018','business_count_2013','business_count_2018']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b64247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use crosswalk to convert ZCTA to ZIP\n",
    "acs_merged['zcta'] = acs_merged['zcta'].astype(int)\n",
    "acs_merged = pd.merge(acs_merged, cross_df, on = 'zcta', how = 'left')\n",
    "acs_merged = acs_merged[acs_merged['zip_code'].astype(str).str.startswith(('10', '11'))].reset_index(drop = True)\n",
    "\n",
    "# some duplicated ZIPs → keep 'ZIP matches ZCTA' but if that isn't true for a zip, then use 'Spaital join to ZCTA'\"ZIP Code to ZCTA Crosswalk.xlsx\"\n",
    "acs_merged['priority'] = (acs_merged['zip_join_type'] == 'Zip matches ZCTA').astype(int)\n",
    "acs_merged = acs_merged.sort_values(by = ['zip_code','priority'], ascending = [True, False]).drop_duplicates(subset = 'zip_code', keep = 'first').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d716cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ZBP and ACS\n",
    "zip_df = pd.merge(zbp_merged, acs_merged, on = 'zip_code', how = 'left')\n",
    "zip_df = zip_df.drop(['zcta','priority'], axis = 1)\n",
    "zip_df = zip_df.dropna().reset_index(drop = True)     # some rows did not merge with population data → drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c67760",
   "metadata": {},
   "source": [
    "### BigQuery public data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77734d",
   "metadata": {},
   "source": [
    "        Zip Code Geometry\n",
    "        Subway Station Ridership and Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "552fefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_geo_df = pd.read_csv('NYC zip geometry.csv')\n",
    "\n",
    "#separate geometry and boroughs\n",
    "sub_geo = sub_df[['station_complex_name','borough','station_geom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da525a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIP level population and employment still contains ZIPs that are not in NYC\n",
    "# geometry data contains only NYC, excluding Staten Island\n",
    "nyc_df = pd.merge(zip_geo_df, zip_df, on = 'zip_code', how = 'left')\n",
    "nyc_df = nyc_df.dropna().reset_index(drop = True)       # 1 row did not merge with population data → drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42eca77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into geo dataframe\n",
    "sub_df['station_geom'] = sub_df['station_geom'].astype(str).apply(wkt.loads)                # there seems to be mixed classes → force everything into a string before converting to geometry\n",
    "sub_gdf = gpd.GeoDataFrame(sub_df, geometry = 'station_geom', crs = 'EPSG:4326')\n",
    "nyc_df['zip_code_geom'] = nyc_df['zip_code_geom'].apply(wkt.loads)\n",
    "nyc_gdf = gpd.GeoDataFrame(nyc_df, geometry = 'zip_code_geom', crs = 'EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0299f3",
   "metadata": {},
   "source": [
    "### Spatial Buffering → what zip codes are within 0.5 miles of a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69395cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change crs for better accuracy → feet instead of degrees\n",
    "sub_gdf = sub_gdf.to_crs(epsg = 2263)\n",
    "nyc_gdf = nyc_gdf.to_crs(epsg = 2263)\n",
    "\n",
    "# create a 0.5 mile buffer & set this as the active geometry column\n",
    "sub_gdf['buffer_geom'] = sub_gdf.geometry.buffer(2640)      # 1 mile = 5280 feet\n",
    "sub_gdf = sub_gdf.set_geometry('buffer_geom')\n",
    "\n",
    "# only keep station, borough and the buffer geom\n",
    "sub_gdf = sub_gdf[['station_complex_name','borough','buffer_geom']]\n",
    "\n",
    "# spatial join → get zip codes that intersect with the buffer\n",
    "zips_near_station = gpd.sjoin(nyc_gdf, sub_gdf[['station_complex_name','borough','buffer_geom']], how = 'inner', predicate = 'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df980362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join row multiplies → a row for each station to zip combination → groupby on stations\n",
    "spatial_df = zips_near_station.groupby('station_complex_name').agg({\n",
    "    \n",
    "    # SUM variables that are counts\n",
    "    'employee_count_2013':'sum',\n",
    "    'employee_count_2018':'sum',\n",
    "    'business_count_2013':'sum',\n",
    "    'business_count_2018':'sum',\n",
    "    'pop_2013':'sum',\n",
    "    'pop_2018':'sum',\n",
    "    'male_pop_2013':'sum',\n",
    "    'male_pop_2018':'sum',\n",
    "    'female_pop_2013':'sum',\n",
    "    'female_pop_2018':'sum',\n",
    "    'college_early_prof_2013':'sum',\n",
    "    'college_early_prof_2018':'sum',\n",
    "    'young_prof_2013':'sum',\n",
    "    'young_prof_2018':'sum',\n",
    "    'housing_units_2013':'sum',\n",
    "    'housing_units_2018':'sum',\n",
    "    'renter_occupied_2013':'sum',\n",
    "    'renter_occupied_2018':'sum',\n",
    "    'occupied_total_2013':'sum',\n",
    "    'occupied_total_2018':'sum',\n",
    "\n",
    "    # use MEAN for variables that are medians\n",
    "    'median_age_2013':'mean',\n",
    "    'median_age_2018':'mean',\n",
    "    'median_income_2013':'mean',\n",
    "    'median_income_2018':'mean',\n",
    "    'median_rent_2013':'mean',\n",
    "    'median_rent_2018':'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "735660c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back ridership data and add borough for control\n",
    "spatial_df = pd.merge(spatial_df, sub_df, on = 'station_complex_name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef67265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    station_complex_name  employee_count_2013  employee_count_2018  \\\n",
      "404        WTC Cortlandt             267468.0             301829.0   \n",
      "\n",
      "     business_count_2013  business_count_2018  pop_2013  pop_2018  \\\n",
      "404              12709.0              12520.0   79710.0   88822.0   \n",
      "\n",
      "     male_pop_2013  male_pop_2018  female_pop_2013  ...  median_rent_2013  \\\n",
      "404        79710.0        88822.0          40084.0  ...          1866.375   \n",
      "\n",
      "     median_rent_2018  routes  ridership_2013  ridership_2018  complex_id  \\\n",
      "404            2985.5       1             0.0          3558.0         328   \n",
      "\n",
      "       borough                  station_geom  complex_id_unique  route_count  \n",
      "404  Manhattan  POINT (-74.012188 40.711835)                  Y            1  \n",
      "\n",
      "[1 rows x 35 columns]\n",
      "Empty DataFrame\n",
      "Columns: [station_complex_name, employee_count_2013, employee_count_2018, business_count_2013, business_count_2018, pop_2013, pop_2018, male_pop_2013, male_pop_2018, female_pop_2013, female_pop_2018, college_early_prof_2013, college_early_prof_2018, young_prof_2013, young_prof_2018, housing_units_2013, housing_units_2018, renter_occupied_2013, renter_occupied_2018, occupied_total_2013, occupied_total_2018, median_age_2013, median_age_2018, median_income_2013, median_income_2018, median_rent_2013, median_rent_2018, routes, ridership_2013, ridership_2018, complex_id, borough, station_geom, complex_id_unique, route_count]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# the WTC Cortlandt station was still being rebuilt and didn't reopen until 2018 → drop any rows with 0 values for ridership, population, employees\n",
    "print(spatial_df[spatial_df['ridership_2013'] == 0])\n",
    "print(spatial_df[spatial_df['ridership_2018'] == 0])\n",
    "\n",
    "spatial_df = spatial_df[(spatial_df['ridership_2013'] > 0) & (spatial_df['ridership_2018'] > 0)]\n",
    "spatial_df = spatial_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9289b9",
   "metadata": {},
   "source": [
    "### Add Subway Line Group Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b38c1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define route groups\n",
    "route_groups = {\n",
    "    'line_ACE': ['A', 'C', 'E'],\n",
    "    'line_123': ['1', '2', '3'],\n",
    "    'line_BDFM': ['B', 'D', 'F', 'M'],\n",
    "    'line_456': ['4', '5', '6'],\n",
    "    'line_NQRW': ['N', 'Q', 'R', 'W'],\n",
    "    'line_7': ['7'],\n",
    "    'line_L': ['L'],\n",
    "    'line_G': ['G'],\n",
    "    'line_JZ': ['J', 'Z']\n",
    "}\n",
    "\n",
    "# Split routes column into lists\n",
    "spatial_df['route_list'] = spatial_df['routes'].str.split(' ')\n",
    "\n",
    "# Create dummy columns\n",
    "for group_name, lines in route_groups.items():\n",
    "    spatial_df[group_name] = spatial_df['route_list'].apply(lambda x: any(route in lines for route in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a2b65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change boolean calues to binary\n",
    "bool_cols = spatial_df.select_dtypes(include=['bool']).columns\n",
    "spatial_df[bool_cols] = spatial_df[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2e5ce",
   "metadata": {},
   "source": [
    "### Separate datasets for Absoulte Change Model and Percent Change Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f924d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "perc_reg_df = spatial_df[['station_complex_name','borough','routes','route_count','station_geom',\n",
    "                          'line_ACE','line_123','line_BDFM','line_456','line_NQRW','line_7','line_L','line_G','line_JZ']]\n",
    "\n",
    "absol_reg_df = spatial_df[['station_complex_name','borough','routes','route_count','station_geom',\n",
    "                           'line_ACE','line_123','line_BDFM','line_456','line_NQRW','line_7','line_L','line_G','line_JZ','ridership_2013']]     # include baseline ridership for absolute model for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7212337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['rider_change'] = (spatial_df['ridership_2018'] - spatial_df['ridership_2013']) / spatial_df['ridership_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['emp_change'] = (spatial_df['employee_count_2018'] - spatial_df['employee_count_2013']) / spatial_df['employee_count_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['bus_change'] = (spatial_df['business_count_2018'] - spatial_df['business_count_2013']) / spatial_df['business_count_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['pop_change'] = (spatial_df['pop_2018'] - spatial_df['pop_2013']) / spatial_df['pop_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['women_share_change'] = ((spatial_df['female_pop_2018'] / spatial_df['pop_2018']) - (spatial_df['female_pop_2013'] / spatial_df['pop_2013'])) * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['med_age_change'] = (spatial_df['median_age_2018'] - spatial_df['median_age_2013']) / spatial_df['median_age_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['college_age_change'] = (spatial_df['college_early_prof_2018'] - spatial_df['college_early_prof_2013']) / spatial_df['college_early_prof_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['young_prof_age_change'] = (spatial_df['young_prof_2018'] - spatial_df['young_prof_2013']) / spatial_df['young_prof_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['med_income_change'] = (spatial_df['median_income_2018'] - spatial_df['median_income_2013']) / spatial_df['median_income_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['med_rent_change'] = (spatial_df['median_rent_2018'] - spatial_df['median_rent_2013']) / spatial_df['median_rent_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['housing_units_change'] = (spatial_df['housing_units_2018'] - spatial_df['housing_units_2013']) / spatial_df['housing_units_2013'] * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\798710381.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perc_reg_df['renter_share_change'] = ((spatial_df['renter_occupied_2018'] / spatial_df['occupied_total_2018']) - (spatial_df['renter_occupied_2013'] / spatial_df['occupied_total_2013'])) * 100\n"
     ]
    }
   ],
   "source": [
    "# percent change\n",
    "\n",
    "# add growth / decline\n",
    "perc_reg_df['rider_change'] = (spatial_df['ridership_2018'] - spatial_df['ridership_2013']) / spatial_df['ridership_2013'] * 100\n",
    "\n",
    "# employees + business\n",
    "perc_reg_df['emp_change'] = (spatial_df['employee_count_2018'] - spatial_df['employee_count_2013']) / spatial_df['employee_count_2013'] * 100\n",
    "perc_reg_df['bus_change'] = (spatial_df['business_count_2018'] - spatial_df['business_count_2013']) / spatial_df['business_count_2013'] * 100\n",
    "\n",
    "# population\n",
    "perc_reg_df['pop_change'] = (spatial_df['pop_2018'] - spatial_df['pop_2013']) / spatial_df['pop_2013'] * 100\n",
    "perc_reg_df['women_share_change'] = ((spatial_df['female_pop_2018'] / spatial_df['pop_2018']) - (spatial_df['female_pop_2013'] / spatial_df['pop_2013'])) * 100\n",
    "\n",
    "# age\n",
    "perc_reg_df['med_age_change'] = (spatial_df['median_age_2018'] - spatial_df['median_age_2013']) / spatial_df['median_age_2013'] * 100\n",
    "perc_reg_df['college_age_change'] = (spatial_df['college_early_prof_2018'] - spatial_df['college_early_prof_2013']) / spatial_df['college_early_prof_2013'] * 100\n",
    "perc_reg_df['young_prof_age_change'] = (spatial_df['young_prof_2018'] - spatial_df['young_prof_2013']) / spatial_df['young_prof_2013'] * 100\n",
    "\n",
    "# income\n",
    "perc_reg_df['med_income_change'] = (spatial_df['median_income_2018'] - spatial_df['median_income_2013']) / spatial_df['median_income_2013'] * 100\n",
    "\n",
    "# housing\n",
    "perc_reg_df['med_rent_change'] = (spatial_df['median_rent_2018'] - spatial_df['median_rent_2013']) / spatial_df['median_rent_2013'] * 100\n",
    "perc_reg_df['housing_units_change'] = (spatial_df['housing_units_2018'] - spatial_df['housing_units_2013']) / spatial_df['housing_units_2013'] * 100\n",
    "perc_reg_df['renter_share_change'] = ((spatial_df['renter_occupied_2018'] / spatial_df['occupied_total_2018']) - (spatial_df['renter_occupied_2013'] / spatial_df['occupied_total_2013'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23b23547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['rider_change'] = spatial_df['ridership_2018'] - spatial_df['ridership_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['emp_change'] = spatial_df['employee_count_2018'] - spatial_df['employee_count_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['bus_change'] = spatial_df['business_count_2018'] - spatial_df['business_count_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['pop_change'] = spatial_df['pop_2018'] - spatial_df['pop_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['women_share_change'] = ((spatial_df['female_pop_2018'] / spatial_df['pop_2018']) - (spatial_df['female_pop_2013'] / spatial_df['pop_2013'])) * 100\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['med_age_change'] = spatial_df['median_age_2018'] - spatial_df['median_age_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['college_age_change'] = spatial_df['college_early_prof_2018'] - spatial_df['college_early_prof_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['young_prof_age_change'] = spatial_df['young_prof_2018'] - spatial_df['young_prof_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['med_income_change'] = spatial_df['median_income_2018'] - spatial_df['median_income_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['med_rent_change'] = spatial_df['median_rent_2018'] - spatial_df['median_rent_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['housing_units_change'] = spatial_df['housing_units_2018'] - spatial_df['housing_units_2013']\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\3409092991.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  absol_reg_df['renter_share_change'] = ((spatial_df['renter_occupied_2018'] / spatial_df['occupied_total_2018']) - (spatial_df['renter_occupied_2013'] / spatial_df['occupied_total_2013'])) * 100\n"
     ]
    }
   ],
   "source": [
    "# add growth / decline\n",
    "absol_reg_df['rider_change'] = spatial_df['ridership_2018'] - spatial_df['ridership_2013']\n",
    "\n",
    "# employees + business\n",
    "absol_reg_df['emp_change'] = spatial_df['employee_count_2018'] - spatial_df['employee_count_2013']\n",
    "absol_reg_df['bus_change'] = spatial_df['business_count_2018'] - spatial_df['business_count_2013']\n",
    "\n",
    "# population\n",
    "absol_reg_df['pop_change'] = spatial_df['pop_2018'] - spatial_df['pop_2013']\n",
    "absol_reg_df['women_share_change'] = ((spatial_df['female_pop_2018'] / spatial_df['pop_2018']) - (spatial_df['female_pop_2013'] / spatial_df['pop_2013'])) * 100\n",
    "\n",
    "# age\n",
    "absol_reg_df['med_age_change'] = spatial_df['median_age_2018'] - spatial_df['median_age_2013']\n",
    "absol_reg_df['college_age_change'] = spatial_df['college_early_prof_2018'] - spatial_df['college_early_prof_2013']\n",
    "absol_reg_df['young_prof_age_change'] = spatial_df['young_prof_2018'] - spatial_df['young_prof_2013']\n",
    "\n",
    "# income\n",
    "absol_reg_df['med_income_change'] = spatial_df['median_income_2018'] - spatial_df['median_income_2013']\n",
    "\n",
    "# housing\n",
    "absol_reg_df['med_rent_change'] = spatial_df['median_rent_2018'] - spatial_df['median_rent_2013']\n",
    "absol_reg_df['housing_units_change'] = spatial_df['housing_units_2018'] - spatial_df['housing_units_2013']\n",
    "absol_reg_df['renter_share_change'] = ((spatial_df['renter_occupied_2018'] / spatial_df['occupied_total_2018']) - (spatial_df['renter_occupied_2013'] / spatial_df['occupied_total_2013'])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738ec98",
   "metadata": {},
   "source": [
    "### Save off dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4fc4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for regressions\n",
    "perc_reg_df.to_csv('percent change regression data.csv', index = False)\n",
    "absol_reg_df.to_csv('absolute change regression data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "028fa9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\1559006371.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations_df[['ridership_2013','ridership_2018']] = stations_df[['ridership_2013','ridership_2018']].astype(int)\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_16708\\1559006371.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations_df['ridership_perc_change'] = round((stations_df['ridership_2018'] - stations_df['ridership_2013']) / stations_df['ridership_2013'] * 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# zip codes that are within the buffer zone → for mapping\n",
    "buffer_zip_list = zips_near_station['zip_code'].unique()\n",
    "buffer_zip_df = nyc_df[nyc_df['zip_code'].isin(buffer_zip_list)]\n",
    "\n",
    "buffer_zip_df = buffer_zip_df[['zip_code','zip_code_geom','pop_2013','pop_2018','employee_count_2013','employee_count_2018']]\n",
    "buffer_zip_df[['pop_2013','pop_2018','employee_count_2013','employee_count_2018']] = buffer_zip_df[['pop_2013','pop_2018','employee_count_2013','employee_count_2018']].astype(int)\n",
    "\n",
    "buffer_zip_df['pop_perc_change'] = round((buffer_zip_df['pop_2018'] - buffer_zip_df['pop_2013']) / buffer_zip_df['pop_2013'] * 100, 1)\n",
    "buffer_zip_df['emp_perc_change'] = round((buffer_zip_df['employee_count_2018'] - buffer_zip_df['employee_count_2013']) / buffer_zip_df['employee_count_2013'] * 100, 1)\n",
    "\n",
    "buffer_zip_df.to_csv('zip codes - mapping.csv', index = False)\n",
    "\n",
    "# simplified station df → for mapping\n",
    "stations_df = spatial_df[['station_complex_name','station_geom','ridership_2013','ridership_2018','routes']]\n",
    "\n",
    "stations_df[['ridership_2013','ridership_2018']] = stations_df[['ridership_2013','ridership_2018']].astype(int)\n",
    "stations_df['ridership_perc_change'] = round((stations_df['ridership_2018'] - stations_df['ridership_2013']) / stations_df['ridership_2013'] * 100, 1)\n",
    "\n",
    "stations_df.to_csv('stations - mapping.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
